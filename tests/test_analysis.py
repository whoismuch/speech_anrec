import sys
from pathlib import Path
sys.path.append(str(Path(__file__).resolve().parent.parent))
from pathlib import Path

from models.analysis import analyze_transcript, save_report
import pandas as pd

INPUT_DIR = Path("tests/data/transcripts/")
OUTPUT_DIR = Path("tests/data/output/text_analysis/")
OUTPUT_DIR.mkdir(parents=True, exist_ok=True)

summary_rows = []

for txt_file in INPUT_DIR.glob("*.txt"):
    text = txt_file.read_text(encoding="utf-8")
    report = analyze_transcript(text)

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω—ã–π –æ—Ç—á—ë—Ç
    save_path = OUTPUT_DIR / f"{txt_file.stem}_report.txt"
    save_report(report, save_path)
    print(f"‚úÖ –û—Ç—á—ë—Ç —Å–æ–∑–¥–∞–Ω: {save_path}")

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å—Ç—Ä–æ–∫—É –¥–ª—è —Ç–∞–±–ª–∏—Ü—ã
    metrics = report["metrics"]
    summary_rows.append({
        "–§–∞–π–ª": txt_file.name,
        "–°–ª–æ–≤": metrics["–û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ª–æ–≤"],
        "–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö": metrics["–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤"],
        "TTR": metrics["Type-Token Ratio (TTR)"],
        "–î–ª–∏–Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è": metrics["–°—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è"],
        "–ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π": metrics["–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π"],
        "–°–ª–æ–≤-–ø–∞—Ä–∞–∑–∏—Ç–æ–≤": metrics["–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ª–æ–≤-–ø–∞—Ä–∞–∑–∏—Ç–æ–≤"],
        "–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ø–∞—Ä–∞–∑–∏—Ç–æ–≤": metrics["–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤-–ø–∞—Ä–∞–∑–∏—Ç–æ–≤"]
    })

# –°–æ–∑–¥–∞—ë–º –∏—Ç–æ–≥–æ–≤—É—é —Ç–∞–±–ª–∏—Ü—É
summary_df = pd.DataFrame(summary_rows)
summary_path = OUTPUT_DIR / "summary_table.csv"
summary_df.to_csv(summary_path, index=False, encoding="utf-8")
print(f"\nüìä –¢–∞–±–ª–∏—Ü–∞ –º–µ—Ç—Ä–∏–∫ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {summary_path}\n")

# –ü–µ—á–∞—Ç—å —Ç–∞–±–ª–∏—Ü—ã –≤ –∫–æ–Ω—Å–æ–ª—å
print(summary_df.to_markdown(index=False))
