import numpy as np
import soundfile as sf
import torch
import torchaudio

def overlaps_with_existing(start, end, existing_intervals):
    for existing_start, existing_end in existing_intervals:
        if not (end <= existing_start or start >= existing_end):
            return True
    return False

def combine_segments(mono_segments, target_segments, target_speaker, y, sr, output_path):
    print("üîú –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã —Ü–µ–ª–µ–≤–æ–≥–æ —Å–ø–∏–∫–µ—Ä–∞...")

    all_chunks = []
    used_intervals = []

    # --- 1. Mono —Å–µ–≥–º–µ–Ω—Ç—ã
    for start, end, speaker in mono_segments:
        if speaker == target_speaker:
            start_sample = int(start * sr)
            end_sample = int(end * sr)
            chunk = y[start_sample:end_sample]
            all_chunks.append((start, chunk))
            used_intervals.append((start, end))

    # --- 2. –†–∞–∑–¥–µ–ª—ë–Ω–Ω—ã–µ —Å–µ–≥–º–µ–Ω—Ç—ã (–±–µ–∑ –ø–µ—Ä–µ–∫—Ä—ã—Ç–∏—è)
    resampler = torchaudio.transforms.Resample(orig_freq=8000, new_freq=sr)

    for path, start, end in target_segments:
        if overlaps_with_existing(start, end, used_intervals):
            continue  # –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç

        chunk, chunk_sr = sf.read(path)

        if chunk_sr != sr:
            if chunk.ndim == 1:
                chunk = torch.tensor(chunk, dtype=torch.float32).unsqueeze(0)
            else:
                chunk = torch.tensor(chunk.T, dtype=torch.float32)
            chunk = resampler(chunk).numpy()
            chunk = chunk.mean(axis=0) if chunk.ndim > 1 else chunk  # –º–æ–Ω–æ
        elif chunk.ndim == 2:
            chunk = chunk.mean(axis=1)

        all_chunks.append((start, chunk))
        used_intervals.append((start, end))

    # --- –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –∏ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ
    all_chunks.sort(key=lambda x: x[0])

    if all_chunks:
        combined_audio = np.concatenate([chunk for _, chunk in all_chunks])
    else:
        print("‚ö†Ô∏è –ù–µ—Ç –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤ ‚Äî —Å–æ–∑–¥–∞—ë—Ç—Å—è –ø—É—Å—Ç–æ–π WAV.")
        combined_audio = np.zeros(1, dtype=np.float32)  # 1 —Å–µ–º–ø–ª —Ç–∏—à–∏–Ω—ã –¥–ª—è –≤–∞–ª–∏–¥–Ω–æ–≥–æ WAV

    # --- –°–æ—Ö—Ä–∞–Ω—è–µ–º
    sf.write(output_path, combined_audio, sr)
    print(f"‚úÖ –§–∏–Ω–∞–ª—å–Ω—ã–π WAV —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {output_path}")
