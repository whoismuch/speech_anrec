import numpy as np
from resemblyzer import VoiceEncoder, preprocess_wav
from sklearn.metrics.pairwise import cosine_similarity
import librosa

def identify_target_speaker(reference_path, audio_path, mono_segments, sample_rate=16000):
    print("üîú –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ü–µ–ª–µ–≤–æ–≥–æ —Å–ø–∏–∫–µ—Ä–∞...")

    # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏ –∫–æ–¥–∏—Ä—É–µ–º —ç—Ç–∞–ª–æ–Ω–Ω—ã–π –≥–æ–ª–æ—Å
    encoder = VoiceEncoder()
    ref_wav = preprocess_wav(reference_path)
    ref_embed = encoder.embed_utterance(ref_wav)

    # –ó–∞–≥—Ä—É–∂–∞–µ–º –æ—Å–Ω–æ–≤–Ω–æ–µ –∞—É–¥–∏–æ
    y, sr = librosa.load(audio_path, sr=sample_rate)

    MIN_DURATION = 1.0  # –≤ —Å–µ–∫—É–Ω–¥–∞—Ö

    speaker_embeddings = {}
    for start, end, speaker in mono_segments:
        if end - start < MIN_DURATION:
            continue

        segment_audio = y[int(start * sr):int(end * sr)]
        try:
            wav = preprocess_wav(segment_audio, source_sr=sr)
            embed = encoder.embed_utterance(wav)
            speaker_embeddings.setdefault(speaker, []).append(embed)
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ —Å–µ–≥–º–µ–Ω—Ç–∞ {start:.2f}-{end:.2f}: {e}")

    # –£—Å—Ä–µ–¥–Ω—è–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –∏ —Å—Ä–∞–≤–Ω–∏–≤–∞–µ–º
    mean_embeddings = {s: np.mean(np.vstack(e), axis=0) for s, e in speaker_embeddings.items()}
    similarities = {s: cosine_similarity(ref_embed.reshape(1, -1), emb.reshape(1, -1))[0][0] for s, emb in mean_embeddings.items()}

    print("\n –°—Ö–æ–¥—Å—Ç–≤–æ —Å–ø–∏–∫–µ—Ä–æ–≤ —Å —ç—Ç–∞–ª–æ–Ω–æ–º:")
    for s, sim in sorted(similarities.items(), key=lambda x: x[1], reverse=True):
        print(f"  - {s}: {sim:.4f}")

    print("üîç Similarities:", similarities)
    if not similarities or max(similarities.values()) < 0.75:
        print("‚ö†Ô∏è –ù–µ—Ç –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö —Å–µ–≥–º–µ–Ω—Ç–æ–≤ –¥–ª—è –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Ü–µ–ª–µ–≤–æ–≥–æ —Å–ø–∏–∫–µ—Ä–∞.")
        return (
            "NOT_FOUND",
            np.zeros_like(ref_embed),
            np.array([]),
            sr,
            encoder
        )

    target = max(similarities, key=similarities.get)
    print(f"\n ‚úÖ–¶–µ–ª–µ–≤–æ–π —Å–ø–∏–∫–µ—Ä: {target} (–ø–æ—Ö–æ–∂–µ—Å—Ç—å: {similarities[target]:.4f})")

    return target, ref_embed, y, sr, encoder

def get_encoder():
    return VoiceEncoder()

def extract_embedding(audio_path, encoder, sample_rate=16000):
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —ç–º–±–µ–¥–¥–∏–Ω–≥ –∞—É–¥–∏–æ—Ñ–∞–π–ª–∞ —Å –ø–æ–º–æ—â—å—é –ø–µ—Ä–µ–¥–∞–Ω–Ω–æ–≥–æ encoder.
    """
    wav = preprocess_wav(audio_path)
    return encoder.embed_utterance(wav)

