import numpy as np
from resemblyzer import VoiceEncoder, preprocess_wav
from sklearn.metrics.pairwise import cosine_similarity
import librosa

def identify_target_speaker(reference_path, audio_path, mono_segments, sample_rate=16000):
    print("üîú –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ü–µ–ª–µ–≤–æ–≥–æ —Å–ø–∏–∫–µ—Ä–∞...")

    # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏ –∫–æ–¥–∏—Ä—É–µ–º —ç—Ç–∞–ª–æ–Ω–Ω—ã–π –≥–æ–ª–æ—Å
    encoder = VoiceEncoder()
    ref_wav = preprocess_wav(reference_path)
    ref_embed = encoder.embed_utterance(ref_wav)

    # –ó–∞–≥—Ä—É–∂–∞–µ–º –æ—Å–Ω–æ–≤–Ω–æ–µ –∞—É–¥–∏–æ
    y, sr = librosa.load(audio_path, sr=sample_rate)

    speaker_embeddings = {}
    for start, end, speaker in mono_segments:
        segment_audio = y[int(start * sr):int(end * sr)]
        try:
            wav = preprocess_wav(segment_audio, source_sr=sr)
            embed = encoder.embed_utterance(wav)
            speaker_embeddings.setdefault(speaker, []).append(embed)
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ —Å–µ–≥–º–µ–Ω—Ç–∞ {start:.2f}-{end:.2f}: {e}")

    # –£—Å—Ä–µ–¥–Ω—è–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –∏ —Å—Ä–∞–≤–Ω–∏–≤–∞–µ–º
    mean_embeddings = {s: np.mean(np.vstack(e), axis=0) for s, e in speaker_embeddings.items()}
    similarities = {s: cosine_similarity(ref_embed.reshape(1, -1), emb.reshape(1, -1))[0][0] for s, emb in mean_embeddings.items()}

    print("\n –°—Ö–æ–¥—Å—Ç–≤–æ —Å–ø–∏–∫–µ—Ä–æ–≤ —Å —ç—Ç–∞–ª–æ–Ω–æ–º:")
    for s, sim in sorted(similarities.items(), key=lambda x: x[1], reverse=True):
        print(f"  - {s}: {sim:.4f}")

    target = max(similarities, key=similarities.get)
    print(f"\n ‚úÖ–¶–µ–ª–µ–≤–æ–π —Å–ø–∏–∫–µ—Ä: {target} (–ø–æ—Ö–æ–∂–µ—Å—Ç—å: {similarities[target]:.4f})")

    return target, ref_embed, y, sr, encoder
