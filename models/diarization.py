# models/diarization.py

from pyannote.audio import Pipeline

def run_diarization(audio_path: str, hf_token: str):
    """
    –í—ã–ø–æ–ª–Ω—è–µ—Ç –¥–∏–∞—Ä–∏–∑–∞—Ü–∏—é –∞—É–¥–∏–æ—Ñ–∞–π–ª–∞.

    :param audio_path: –ø—É—Ç—å –∫ –∞—É–¥–∏–æ—Ñ–∞–π–ª—É (wav)
    :param hf_token: Hugging Face —Ç–æ–∫–µ–Ω –¥–ª—è pyannote
    :return: mono_segments, multi_segments, full diarization object
    """
    print("üîç –ó–∞–ø—É—Å–∫ –¥–∏–∞—Ä–∏–∑–∞—Ü–∏–∏...")
    pipeline = Pipeline.from_pretrained("pyannote/speaker-diarization", use_auth_token=hf_token)

    diarization = pipeline(audio_path)

    mono_segments = []
    multi_segments = []

    for turn, _, speaker in diarization.itertracks(yield_label=True):
        overlapping = diarization.crop(turn, mode="loose").labels()
        if len(overlapping) == 1:
            mono_segments.append((turn.start, turn.end, speaker))
        else:
            multi_segments.append((turn.start, turn.end, overlapping))  # —Å–æ—Ö—Ä–∞–Ω–∏–º —Å–ø–∏—Å–æ–∫ —Å–ø–∏–∫–µ—Ä–æ–≤

    print(f"‚úÖ –î–∏–∞—Ä–∏–∑–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞. mono: {len(mono_segments)}, multi: {len(multi_segments)}")
    return mono_segments, multi_segments, diarization
