# models/asr.py

import whisper

def transcribe_audio(audio_path: str, model_size: str = "base") -> str:
    """
    –†–∞—Å–ø–æ–∑–Ω–∞—ë—Ç —Ä–µ—á—å –≤ –∞—É–¥–∏–æ—Ñ–∞–π–ª–µ —Å –ø–æ–º–æ—â—å—é Whisper.

    :param audio_path: –ø—É—Ç—å –∫ WAV-—Ñ–∞–π–ª—É
    :param model_size: "tiny", "base", "small", "medium", "large"
    :return: —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
    """
    print(f"üìù –†–∞—Å–ø–æ–∑–Ω–∞—ë–º —Ä–µ—á—å (–º–æ–¥–µ–ª—å: {model_size})...")
    model = whisper.load_model(model_size)
    result = model.transcribe(audio_path)

    print("‚úÖ –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ.")
    return result["text"]
