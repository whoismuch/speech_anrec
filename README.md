# Speech Feedback System

üß† –ò–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ —É—Å—Ç–Ω–æ–π —Ä–µ—á–∏ –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –ø–æ –µ—ë —É–ª—É—á—à–µ–Ω–∏—é.

---

## ‚ú® –í–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏

* –í—ã–¥–µ–ª—è–µ—Ç —Ä–µ—á—å –æ–¥–Ω–æ–≥–æ —Ü–µ–ª–µ–≤–æ–≥–æ –≥–æ–≤–æ—Ä—è—â–µ–≥–æ –∏–∑ —à—É–º–Ω—ã—Ö –∏ –º–Ω–æ–≥–æ—Å–ø–∏–∫–µ—Ä–Ω—ã—Ö –∞—É–¥–∏–æ–∑–∞–ø–∏—Å–µ–π
* –†–∞—Å–ø–æ–∑–Ω–∞—ë—Ç —Ä–µ—á—å —Å –ø–æ–º–æ—â—å—é Whisper
* –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Ä–µ—á–∏: TTR, –¥–ª–∏–Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π, —Å–ª–æ–≤–∞-–ø–∞—Ä–∞–∑–∏—Ç—ã –∏ –¥—Ä.
* –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —É–ª—É—á—à–µ–Ω–∏—é —Ä–µ—á–∏ —Å –ø–æ–º–æ—â—å—é LLM

---

## ‚ö°Ô∏è –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç

### üîß –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π

```bash
python -m venv .venv
source .venv/bin/activate  # –∏–ª–∏ .venv\Scripts\activate –Ω–∞ Windows
pip install -r requirements.txt
```

### üöÄ –ó–∞–ø—É—Å–∫ –ø–∞–π–ø–ª–∞–π–Ω–∞

```bash
python run_pipeline.py \
  --input data/input/main_audio.wav \
  --reference data/input/reference.wav \
  --output data/output \
  --hf_token YOUR_HF_TOKEN
```

–î–æ–±–∞–≤—å—Ç–µ —Ñ–ª–∞–≥ --debug, —á—Ç–æ–±—ã —Å–æ—Ö—Ä–∞–Ω—è—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å –ø–æ—Å—Ç—Ñ–∏–∫—Å–æ–º –∏–º–µ–Ω–∏ –≤—Ö–æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞:

python run_pipeline.py \
  --input data/input/meeting1.wav \
  --reference data/input/ali.wav \
  --output data/output \
  --debug

–§–∞–π–ª—ã –±—É–¥—É—Ç –Ω–∞–∑—ã–≤–∞—Ç—å—Å—è, –Ω–∞–ø—Ä–∏–º–µ—Ä: transcript_meeting1.txt, feedback_meeting1.md –∏ —Ç.–ø.



### üîë –ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)

–°–æ–∑–¥–∞–π—Ç–µ —Ñ–∞–π–ª `.env` –∏ –¥–æ–±–∞–≤—å—Ç–µ:

```env
HF_TOKEN=your_huggingface_token
OPENROUTER_API_KEY=your_openrouter_api_key_here
```

---

## üöÄ –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç —Å conda-–æ–∫—Ä—É–∂–µ–Ω–∏–µ–º

1. –°–∫–ª–æ–Ω–∏—Ä—É–π—Ç–µ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π –∏ –ø–µ—Ä–µ–π–¥–∏—Ç–µ –≤ –ø–∞–ø–∫—É –ø—Ä–æ–µ–∫—Ç–∞.
2. –°–æ–∑–¥–∞–π—Ç–µ –æ–∫—Ä—É–∂–µ–Ω–∏–µ –∏–∑ —Ñ–∞–π–ª–∞ environment.yml:

```bash
conda env create -f environment.yml
```

3. –ê–∫—Ç–∏–≤–∏—Ä—É–π—Ç–µ –æ–∫—Ä—É–∂–µ–Ω–∏–µ:

```bash
conda activate speech_anrec
```

–¢–µ–ø–µ—Ä—å –≤—Å–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –±—É–¥—É—Ç —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏, –∏ –≤—ã —Å–º–æ–∂–µ—Ç–µ –∑–∞–ø—É—Å–∫–∞—Ç—å –ø–∞–π–ø–ª–∞–π–Ω –∏ —Ç–µ—Å—Ç—ã –±–µ–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –Ω–∞—Å—Ç—Ä–æ–µ–∫.

---

## üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥—É–ª—è –≤—ã–¥–µ–ª–µ–Ω–∏—è —Ü–µ–ª–µ–≤–æ–≥–æ –≥–æ–≤–æ—Ä—è—â–µ–≥–æ

–î–ª—è –∑–∞–ø—É—Å–∫–∞ —Ç–µ—Å—Ç–∞ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ:

```bash
python tests/test_speaker_extraction.py \
  --reference tests/data/audio/reference/ali_imba_drink.wav \
  --audio_dir tests/data/audio/ali/test3 \
  --output_dir tests/data/output/speaker_extraction_results_FINAL_FINAL_THESIS_THESIS/ali
```

- `--reference` ‚Äî –ø—É—Ç—å –∫ —ç—Ç–∞–ª–æ–Ω–Ω–æ–º—É .wav —Ñ–∞–π–ª—É —Ü–µ–ª–µ–≤–æ–≥–æ —Å–ø–∏–∫–µ—Ä–∞
- `--audio_dir` ‚Äî –ø–∞–ø–∫–∞ —Å —Ç–µ—Å—Ç–æ–≤—ã–º–∏ .wav —Ñ–∞–π–ª–∞–º–∏ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
- `--output_dir` ‚Äî –ø–∞–ø–∫–∞ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤

–†–µ–∑—É–ª—å—Ç–∞—Ç—ã (–º–µ—Ç—Ä–∏–∫–∏, –≥—Ä–∞—Ñ–∏–∫–∏, —Å–µ–≥–º–µ–Ω—Ç—ã) –±—É–¥—É—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ —É–∫–∞–∑–∞–Ω–Ω–æ–π –ø–∞–ø–∫–µ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ç–µ—Å—Ç–æ–≤–æ–≥–æ —Ñ–∞–π–ª–∞.

---

## üîÑ –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞

```
speech_anrec/
‚îú‚îÄ‚îÄ run_pipeline.py           # –ì–ª–∞–≤–Ω—ã–π —Å–∫—Ä–∏–ø—Ç –∑–∞–ø—É—Å–∫–∞
‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ environment.yml           # –û–∫—Ä—É–∂–µ–Ω–∏–µ conda
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îú‚îÄ‚îÄ diarization.py        # –í—ã–¥–µ–ª–µ–Ω–∏–µ —Å–ø–∏–∫–µ—Ä–æ–≤ (pyannote.audio)
‚îÇ   ‚îú‚îÄ‚îÄ speaker_id.py         # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ü–µ–ª–µ–≤–æ–≥–æ –≥–æ–≤–æ—Ä—è—â–µ–≥–æ
‚îÇ   ‚îú‚îÄ‚îÄ separation.py         # SepFormer separation + speaker ID
‚îÇ   ‚îú‚îÄ‚îÄ combine.py            # –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ WAV
‚îÇ   ‚îú‚îÄ‚îÄ asr.py                # –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ä–µ—á–∏ (Whisper)
‚îÇ   ‚îú‚îÄ‚îÄ analysis.py           # –ê–Ω–∞–ª–∏–∑ —Ç–µ–∫—Å—Ç–∞ —Ä–µ—á–∏
‚îÇ   ‚îî‚îÄ‚îÄ feedback.py           # AI-—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ —á–µ—Ä–µ–∑ OpenRouter
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ input/                # main_audio.wav –∏ reference.wav
‚îÇ   ‚îî‚îÄ‚îÄ output/               # –∏—Ç–æ–≥–æ–≤—ã–µ WAV, —Ç–µ–∫—Å—Ç –∏ –æ—Ç—á—ë—Ç—ã
‚îú‚îÄ‚îÄ tests/                    # –¢–µ—Å—Ç—ã –∏ —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
```

---

## üí° –ü—Ä–∏–º–µ—Ä —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞

- `target_speaker_combined.wav` ‚Äî —Ä–µ—á—å —Ü–µ–ª–µ–≤–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
- `transcript.txt` ‚Äî —Ç–µ–∫—Å—Ç–æ–≤–∞—è —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–∫–∞
- `analysis_report.md` ‚Äî –æ—Ç—á—ë—Ç –ø–æ –º–µ—Ç—Ä–∏–∫–∞–º —Ä–µ—á–∏
- `ai_feedback.md` ‚Äî —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –æ—Ç LLM

---

## üìÑ –õ–∏—Ü–µ–Ω–∑–∏—è

MIT License

---

Created by Khumai Bairamova, 2025
